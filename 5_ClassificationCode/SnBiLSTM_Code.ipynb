{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-s9G-HRzb3u"
      },
      "outputs": [],
      "source": [
        "## Import necessary modules\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, matthews_corrcoef\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import cross_val_score,KFold,StratifiedKFold,cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, LayerNormalization, BatchNormalization, Dropout\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox5VWs5Ozhas"
      },
      "outputs": [],
      "source": [
        "#!pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kCe5sFUzjkS",
        "outputId": "4fb4a442-8d02-42d6-9c56-80390f2bf55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8q4Y_PEzlQM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive/MyDrive/Clathrin/weightedBTGA_Clathrin_Training.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CS2KLQ-9S55",
        "outputId": "bcfe2ceb-c843-4143-8cec-eb62db4e2652"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2421, 970)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Z5JVxeTBznJ5",
        "outputId": "279de593-e0e2-40b7-a023-c0011bc1295a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Initialise the Scaler\n",
        "#scaler = StandardScaler()\n",
        "\n",
        "# To scale data\n",
        "#scaler.fit(df)\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "# Initialise the Scaler\n",
        "#scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B7w2HToKXJG"
      },
      "outputs": [],
      "source": [
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.fillna(999, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKZLM9tl2sd9",
        "outputId": "58f0791e-9569-4b9f-9ed4-65c83125dae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2421, 969)\n",
            "(2421,)\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into features (X) and labels (y)\n",
        "X = df.iloc[:, 0:969].values\n",
        "y = df.iloc [:, 969].values\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4FyfPqpqRzd",
        "outputId": "2428afbd-e975-4b00-9bc9-e34b91ed8e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1936 485 1936 485\n",
            "(1936, 1, 969)\n"
          ]
        }
      ],
      "source": [
        "# Split into training and test set\n",
        "# from sklearn.datasets import make_classification\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#             X, y, test_size = 0.2, random_state=42)\n",
        "# print (len(X_train),len(X_test),len(y_train),len(y_test))\n",
        "# X, y = make_classification(n_samples=2421, n_classes=2, random_state=42)\n",
        "# X_train = np.expand_dims(X_train, axis=1)\n",
        "# print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKC4TIsOj4S9",
        "outputId": "0ed21fcb-93d9-45be-8d21-6755f097f6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2421, 1, 969)\n"
          ]
        }
      ],
      "source": [
        "# Reshape the features to a 3D array for 1D CNN\n",
        "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
        "print(X.shape)\n",
        "\n",
        "# Normalize the features\n",
        "#X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbDgEvBTdwOv",
        "outputId": "5afd5f66-751c-411c-e808-ce2a171de4c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 3s 7ms/step\n",
            "Fold Accuracy: 0.9587628865979382\n",
            "16/16 [==============================] - 3s 7ms/step\n",
            "Fold Accuracy: 0.9566115702479339\n",
            "16/16 [==============================] - 2s 7ms/step\n",
            "Fold Accuracy: 0.9524793388429752\n",
            "16/16 [==============================] - 2s 7ms/step\n",
            "Fold Accuracy: 0.9442148760330579\n",
            "16/16 [==============================] - 3s 13ms/step\n",
            "Fold Accuracy: 0.9566115702479339\n",
            "Accuracy = 0.9537360483939679\n",
            "F1 Score = 0.9503030783758917\n",
            "Precision = 0.9542120585926138\n",
            "Recall = 0.9470546957233636\n",
            "Sensitivity = 0.9470546957233636\n",
            "Specificity = 0.9596476940246734\n",
            "MCC = 0.9075847574951782\n",
            "AUC = 0.9872187595552342\n"
          ]
        }
      ],
      "source": [
        "X_train = X;\n",
        "y_train = y;\n",
        "\n",
        "config = {\n",
        "    'dropout_rate': 0.2,\n",
        "    'activation': 'tanh',\n",
        "    'recurrent_dropout': 0.0,\n",
        "    'kernel_regularizer': l2(0.0001),\n",
        "}\n",
        "\n",
        "def get_model(config):\n",
        "  model = tf.keras.Sequential([\n",
        "    Bidirectional(LSTM(128, return_sequences=True, activation=config['activation'], kernel_regularizer=config['kernel_regularizer'], recurrent_dropout=config['recurrent_dropout']), input_shape=(1, X_train.shape[2])),\n",
        "    Dropout(config['dropout_rate']),\n",
        "    BatchNormalization(),\n",
        "    Bidirectional(LSTM(64, return_sequences=True, activation=config['activation'], kernel_regularizer=config['kernel_regularizer'], recurrent_dropout=config['recurrent_dropout'])),\n",
        "    Dropout(config['dropout_rate']),\n",
        "    BatchNormalization(),\n",
        "    Bidirectional(LSTM(32, activation=config['activation'], kernel_regularizer=config['kernel_regularizer'], recurrent_dropout=config['recurrent_dropout'])),\n",
        "    Dropout(config['dropout_rate']),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "  return model\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "accuracy_list = []\n",
        "f1_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "sensitivity_list = []\n",
        "specificity_list = []\n",
        "mcc_list = []\n",
        "auc_list = []  # Initialize a list for AUC values\n",
        "\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "skfold = StratifiedKFold(n_splits=5, shuffle = True, random_state = 5)\n",
        "for train_index, val_index in skfold.split(X_train, y_train):\n",
        "    # Split the data into training and validation sets for the current fold\n",
        "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
        "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    # Ensure the model is reset for each fold\n",
        "    model = get_model(config)\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6)\n",
        "\n",
        "    # Train the model on the current fold\n",
        "    history=model.fit(X_train_fold, y_train_fold, epochs=40, batch_size=16, verbose=0, validation_split=0.1, callbacks=[reduce_lr])\n",
        "\n",
        "\n",
        "    # Plots the training and validation loss curves from Keras history\n",
        "    # plt.plot(history.history['loss'], label='Train_Loss')\n",
        "    # plt.plot(history.history['val_loss'], label='Validation_Loss')\n",
        "    # plt.plot(history.history['accuracy'], label = 'Train_Accuracy')\n",
        "    # plt.plot(history.history['val_accuracy'], label='Validation_Accuracy')\n",
        "    # plt.title('Training and Validation')\n",
        "    # plt.xlabel('Epoch')\n",
        "    # plt.ylabel('Accuracy_Loss')\n",
        "    # plt.legend()\n",
        "    # plt.grid(True)  # Add grid lines for better readability\n",
        "    # plt.show()\n",
        "\n",
        "    # Evaluate the model on the validation set for the current fold\n",
        "    y_val_pred = model.predict(X_val_fold)\n",
        "    y_val_pred_binary = (y_val_pred > 0.5).astype(int)\n",
        "\n",
        "    # Calculate confusion matrix for the current fold\n",
        "    cm = confusion_matrix(y_val_fold, y_val_pred_binary)\n",
        "    # Calculate AUC for the current fold\n",
        "    auc = roc_auc_score(y_val_fold, y_val_pred)  # Use predicted probabilities for AUC calculation\n",
        "    auc_list.append(auc)\n",
        "\n",
        "\n",
        "    # Calculate performance evaluation metrics for the current fold\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "    TP = cm[1, 1]\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "    accuracy_list.append(accuracy)\n",
        "    print(\"Fold Accuracy:\", accuracy)\n",
        "\n",
        "    # F1-Score\n",
        "    f1 = 2 * TP / float(2 * TP + FP + FN)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "    # Precision\n",
        "    precision = TP / float(TP + FP)\n",
        "    precision_list.append(precision)\n",
        "\n",
        "    # Recall\n",
        "    recall = TP / float(TP + FN)\n",
        "    recall_list.append(recall)\n",
        "\n",
        "    # Sensitivity\n",
        "    sensitivity = TP / float(TP + FN)\n",
        "    sensitivity_list.append(sensitivity)\n",
        "\n",
        "    # Specificity\n",
        "    specificity = TN / float(TN + FP)\n",
        "    specificity_list.append(specificity)\n",
        "\n",
        "    # MCC (Matthews Correlation Coefficient)\n",
        "    mcc = ((TP * TN) - (FP * FN)) / float((np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))) or 1)\n",
        "    mcc_list.append(mcc)\n",
        "\n",
        "# Calculate average performance evaluation metrics across all folds\n",
        "avg_accuracy = np.mean(accuracy_list)\n",
        "avg_f1 = np.mean(f1_list)\n",
        "avg_precision = np.mean(precision_list)\n",
        "avg_recall = np.mean(recall_list)\n",
        "avg_sensitivity = np.mean(sensitivity_list)\n",
        "avg_specificity = np.mean(specificity_list)\n",
        "avg_mcc = np.mean(mcc_list)\n",
        "\n",
        "# Calculate average AUC across all folds\n",
        "avg_auc = np.mean(auc_list)\n",
        "# Print average performance evaluation metrics\n",
        "print(\"Accuracy =\", avg_accuracy)\n",
        "print(\"F1 Score =\", avg_f1)\n",
        "print(\"Precision =\", avg_precision)\n",
        "print(\"Recall =\", avg_recall)\n",
        "print(\"Sensitivity =\", avg_sensitivity)\n",
        "print(\"Specificity =\", avg_specificity)\n",
        "print(\"MCC =\", avg_mcc)\n",
        "print(\"AUC =\", avg_auc)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}